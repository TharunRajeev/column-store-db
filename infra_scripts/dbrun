#!/usr/bin/env python
"""
DB Experiments Runner

Code Structure:
----------------
    - Constants & Parameters:

    - Main function:
        main()

    - Helper functions:
        build_pkgs(), build_pkg(), run_single_test()

    - Utility functions:
        report_cmd_msge(), show_options(), ensure_log_dir_exists(), animate()

    - Color codes and Custom Help Formatter:
        - Colors: ANSI color codes
        - ColorfulHelpFormatter: Custom Help Formatter
"""

import os
import subprocess
import argparse
import sys
import time

from utils import (
    collect_runtimes_from_client_logs,
    ColorfulHelpFormatter,
    Colors,
    ensure_log_dir_exists,
    animate,
    report_cmd_msge,
    show_options,
)

# --------------------- Constants & Parameters -------------------------------
DEFAULT_SEED = 42

M1_NUM_TRIALS = 5
M2_NUM_TRIALS = 5
M3_NUM_TRIALS = 5

IS_IN_DOCKER = os.path.exists("/.dockerenv")
BASE_DIR = (
    os.path.expanduser("~/workspace/h/classes/cs165/mainproj/code/proj/")
    if not IS_IN_DOCKER
    else "/cs165/"
)

# Path constants
DB_SRC_PATH = os.path.expanduser(f"{BASE_DIR}src/")
EXPERIMENTS_PATH = os.path.expanduser(f"{BASE_DIR}experiments/")
TEST_OUTPUT_PATH = os.path.expanduser(f"{BASE_DIR}test_output/")
DATA_GEN_SCRIPTS_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data_gen_scripts/")
GENERATED_DATA_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}generated_data/")
INFRA_SCRIPTS_PATH = os.path.expanduser(f"{BASE_DIR}infra_scripts/")

# Binary paths
SERVER_BINARY = os.path.expanduser(f"{DB_SRC_PATH}server")
CLIENT_BINARY = os.path.expanduser(f"{DB_SRC_PATH}client")
TEST_MILESTONE_SCRIPT = os.path.expanduser(f"{INFRA_SCRIPTS_PATH}test_milestone.sh")
RUN_TEST_SCRIPT = os.path.expanduser(f"{INFRA_SCRIPTS_PATH}run_test.sh")
RUN_EXPERIMENTS_SCRIPT = os.path.expanduser(f"{INFRA_SCRIPTS_PATH}run_experiment.sh")

GEN_DATA_SCRIPT = os.path.expanduser(
    f"{BASE_DIR}project_tests/data_generation_scripts/"
)
GEN_M1_DATA_PY = os.path.expanduser(f"{GEN_DATA_SCRIPT}milestone1.py")
GEN_M2_DATA_PY = os.path.expanduser(f"{GEN_DATA_SCRIPT}milestone2.py")
GEN_M3_DATA_PY = os.path.expanduser(f"{GEN_DATA_SCRIPT}milestone3.py")
GEN_M4_DATA_PY = os.path.expanduser(f"{GEN_DATA_SCRIPT}milestone4.py")


# File extensions and patterns
DSL_EXTENSION = ".dsl"
LOG_EXTENSION = ".log"
OUTPUT_EXTENSION = ".out"
ERROR_EXTENSION = ".err"
TIME_EXTENSION = ".time"

# Default values
DEFAULT_SEED = 42
SERVER_START_DELAY = 1
SERVER_SHUTDOWN_TIMEOUT = 5

# Experiment Queries Paths. These should be generated by the data generation
# scripts, if IN_EXPERIMENTS=True. see data_gen_scripts/milestone{1,2,3,4}.py
M1_QUERIES_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data/milestone1/")
M2_QUERIES_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data/milestone2/")
M3_QUERIES_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data/milestone3/")
M4_QUERIES_PATH = os.path.expanduser(f"{EXPERIMENTS_PATH}data/milestone4/")


# Final parsed data and results paths
PARSED_M1_RESULTS_PATH = f"{BASE_DIR}experiments/results/milestone1/"
PARSED_M2_RESULTS_PATH = f"{BASE_DIR}experiments/results/milestone2/"
PARSED_M3_RESULTS_PATH = f"{BASE_DIR}experiments/results/milestone3/"
PARSED_M4_RESULTS_PATH = f"{BASE_DIR}experiments/results/milestone4/"

# if final results paths do not exist, create them
for path in [
    PARSED_M1_RESULTS_PATH,
    PARSED_M2_RESULTS_PATH,
    PARSED_M3_RESULTS_PATH,
    PARSED_M4_RESULTS_PATH,
]:
    if not os.path.exists(path):
        os.makedirs(path)


# ---------------------------- Main Function ---------------------------------
def main():
    parser = argparse.ArgumentParser(
        description="Run DB Experiments",
        formatter_class=ColorfulHelpFormatter,
    )

    parser.add_argument(
        "-b",
        "--build",
        action="store_true",
        help="Make the `server` and `client` executables",
    )
    parser.add_argument(
        "-t",
        "--test-milestone",
        action="store_true",
        help="Run tests for all milestone up to <m>",
    )

    parser.add_argument(
        "-e",
        "--run-experiment",
        action="store_true",
        help="Run experiments for milestone <m>",
    )

    run_mile_group = parser.add_argument_group("Additional Arguments")
    run_mile_group.add_argument(
        "-m",
        dest="mile_no",
        help="Milestone number",
    )

    args = parser.parse_args()

    if not any(vars(args).values()):
        parser.print_help()
        return

    if args.build and not build_pkg():
        sys.exit(1)

    if args.test_milestone:
        build_pkg(verbose=True)
        run_test_milestones(args.mile_no, verbose=True)
    elif args.run_experiment:
        build_pkg()
        # Needed to ensure necessary data are generated before running
        # experiments no need to do this if tests were run before, but if not,
        #  we need to generate data first (also ensure correctness)
        # run_test_milestones(args.mile_no, verbose=False)
        run_milestone_experiment(args.mile_no)


# ---------------------------- Helper Functions ------------------------------


def run_piped_cmd(cmd, log_file_path, verbose=False):
    out, err = log_file_path + ".out", log_file_path + ".err"

    with open(out, "w", encoding="utf-8") as outfile, open(
        err, "w", encoding="utf-8"
    ) as errfile:
        if verbose:  # useful for development/debug to see real-time output
            additonal_info = {"stdout": out, "stderr": err}
            report_cmd_msge(cmd, additonal_info)

            process = subprocess.Popen(cmd.split())
            process.wait()

        else:  # redirect stdout to file, mostly when running experiments
            process = subprocess.Popen(cmd.split(), stdout=outfile, stderr=errfile)
            animate()
            while process.poll() is None:
                animate()
            print(" Done!")

        return process


def build_pkg(pkg_path=DB_SRC_PATH, verbose=False):
    try:
        os.chdir(pkg_path)
    except OSError:
        print(f"Failed to change directory to {pkg_path}")
        return False

    log_dir = ensure_log_dir_exists(pkg_path)
    if not log_dir:
        return False

    log_file_path = os.path.join(EXPERIMENTS_PATH, "compile.log")
    process = run_piped_cmd("make", log_file_path, verbose=verbose)

    if process.returncode != 0:
        print(
            f"{Colors.RED} ❌ Build returned non-zero exit code:"
            f"{process.returncode}{Colors.ENDC}"
        )

        if os.path.exists(log_file_path):
            print("Showing the build log: ")
            subprocess.run(["cat", log_file_path])
            print(f"Full log file: {Colors.BLUE}{log_file_path}{Colors.ENDC}")

        return False  # Build failed

    print(f"{Colors.GREEN} ✅ BUILD SUCCEEDED {Colors.ENDC}\n\n")
    return True


def run_test_milestones(mile_no, verbose=False):
    # runs the TEST_MILESTONE_SCRIPT with the given milestone number
    print(f"Running tests for milestone up to {mile_no}")
    cmd = f"{TEST_MILESTONE_SCRIPT} {mile_no}"
    log_file_path = os.path.join(EXPERIMENTS_PATH, f"test_m{mile_no}.results")
    process = run_piped_cmd(cmd, log_file_path, verbose=verbose)

    return process.returncode == 0


def run_milestone_experiment(mile_no):
    if mile_no == "1":
        # Probably no need to run multiple trials,
        # m1 have about 10 select queries in each data size/run
        run_m1_experiments(n_trials=M1_NUM_TRIALS)
    elif mile_no == "2":
        run_m2_experiments(n_trials=M2_NUM_TRIALS)
    elif mile_no == "3":
        run_m3_experiment(n_trials=M3_NUM_TRIALS)
    # elif mile_no == "4":
    #     run_m4_experiment()
    else:
        print(f"{Colors.RED}Invalid Milestone Number: {mile_no}{Colors.ENDC}")


def generate_data(mile_no, n, seed, data_dir, kwargs):
    """
    Args:
        mile_no: Milestone number
        n: Number of data points
        seed: Random seed
        data_dir: Directory to save the generated data
        kwargs: Additional arguments for the data generation script
                e.g., number of queries (k) for milestone 2 to batch, etc.
    """
    if mile_no == "1":
        gen_data_script = GEN_M1_DATA_PY
    elif mile_no == "2":
        gen_data_script = GEN_M2_DATA_PY
    elif mile_no == "3":
        gen_data_script = GEN_M3_DATA_PY
    elif mile_no == "4":
        gen_data_script = GEN_M4_DATA_PY
    else:
        print(f"{Colors.RED}Invalid Milestone Number: {mile_no}{Colors.ENDC}")
        return False

    cmd = f"python {gen_data_script}  {n} {seed}"

    run_piped_cmd(cmd, os.path.join(data_dir, f"gen_data_n={n}.log"))


def run_m1_experiments(n_trials=10):
    """
    Run milestone 1 experiments for different data sizes.

    After generating data in IN_EXPERIMENTS mode, M1_QUERIES_PATH should have
    the directories for different data sizes. For example, if n_start=2^10=1024
    and n_end=2^20=1048576, the M1_QUERIES_PATH should look like:
    ```
        .
        ├── 1024
        ├── 1048576
        ├── 131072
        ├── 16384
        ├── 2048
        ├── 262144
        ├── 32768
        ├── 4096
        ├── 524288
        ├── 65536
        └── 8192
    ```
    where each directory contains the DSL files for the queries to be run.

    Args:
        n_start: Starting data size
        n_end: Ending data size
        step_size: Increment size between experiments

    Returns:
        None, server logs with be stored in files named `server_run=<r>.log` in
            the same directory (M1_QUERIES_PATH/n) as the DSL files, where
            `r` is the r-th run.

    """
    print(
        f"{Colors.BOLD}Running Milestone 1 Experiments, n_trials={n_trials}...{Colors.ENDC}"
    )
    try_removing_old_results(PARSED_M1_RESULTS_PATH)

    # run `./run_experiment.sh 1 <data_size>` for each data size
    mile = 1

    for data_size in os.listdir(M1_QUERIES_PATH):
        for run in range(n_trials):
            print(f"data_size={data_size}, run={run}")
            cmd = f"{RUN_EXPERIMENTS_SCRIPT} {mile} {data_size}"
            log_file_path = os.path.join(M1_QUERIES_PATH, data_size, f"run={run}.log")

            process = run_piped_cmd(cmd, log_file_path)

            if process.returncode != 0:
                print(
                    f"{Colors.RED} ❌ Experiment returned non-zero exit code:"
                    f"{process.returncode}{Colors.ENDC}"
                )
                return False
            print(f"{Colors.GREEN} Experiment done! {Colors.ENDC}")
            print(f"parsing logs for data_size={data_size}, run={run}")
            time.sleep(1)

            parsed_file = PARSED_M1_RESULTS_PATH + f"n={data_size}run={run}.csv"
            collect_runtimes_from_client_logs(M1_QUERIES_PATH + data_size, parsed_file)
            print(
                f"{Colors.GREEN}Parsed logs can be found in {parsed_file}{Colors.ENDC}"
            )
    print(f"{Colors.GREEN}All milestone 1 experiments completed{Colors.ENDC}")


def run_m2_experiments(n_trials=10):
    """
    Runs milestone 2's performance tests (16,..., 19) with varying batch size

    cmd: RUN_TEST_SCRIPT $TEST_ID $INPUT_DIR $OUTPUT_DIR

    Pre-calling:
    This should be run after having generated data for experiment by running
    GEN_M2_DATA_PY in "experiment" mode. That should have generated data in the
    M2_QUERIES_PATH with the below directory structure:

    .
    ├── batch_size_1
    │   ├── test16gen.dsl
    │   ├── test16gen.exp
    │   ├── test17gen.dsl
    │   ├── test17gen.exp
    │   ├── test18gen.dsl
    │   ├── test18gen.exp
    │   ├── test19gen.dsl
    │   └── test19gen.exp
    ├── batch_size_128
    │   ├── test16gen.dsl
    │   ├── test16gen.exp
    │   ├── test17gen.dsl

    """
    print(f"{Colors.BOLD}M2 Experiments, n_trials={n_trials}{Colors.ENDC}")

    try_removing_old_results(PARSED_M2_RESULTS_PATH)

    for dir in os.listdir(M2_QUERIES_PATH):
        batch_size = int(dir.split("_")[-1])
        curr_path = M2_QUERIES_PATH + dir

        for run in range(1, n_trials + 1):
            print(f"batch_size={batch_size}, run={run}")

            # Example: ./run_experiment.sh 2 16
            cmd = f"{RUN_EXPERIMENTS_SCRIPT} 2 {batch_size}"
            log_file_path = os.path.join(curr_path, f"run={run}.log")
            report_cmd_msge(cmd, {"stdout": log_file_path + ".out"})

            process = run_piped_cmd(cmd, log_file_path, verbose=True)

            if process.returncode != 0:
                print(
                    f"{Colors.RED} ❌ Experiment returned non-zero exit code:"
                    f"{process.returncode}{Colors.ENDC}"
                )
                return False

            print(f"parsing logs for batch_size={batch_size}, run={run}")
            time.sleep(1)

            parsed_file = (
                PARSED_M2_RESULTS_PATH + f"batch_size={batch_size}run={run}.csv"
            )
            collect_runtimes_from_client_logs(curr_path, parsed_file, milestone=2)
            print(
                f"{Colors.GREEN}Parsed logs can be found in {parsed_file}{Colors.ENDC}"
            )
    print(f"{Colors.GREEN}All milestone 2 experiments completed{Colors.ENDC}")


def run_m3_experiment(n_trials=10):
    """
    Run milestone 3's performance tests (33, ..., 44) with varying data sizes

    cmd: RUN_TEST_SCRIPT $TEST_ID $INPUT_DIR $OUTPUT_DIR

    Assummes M3_QUERIES_PATH has the following structure:
    .
    ├── test33gen.dsl
    ├── test33gen.exp
    ├── ...
    ├── ...
    ├── test44gen.dsl
    └── test44gen.exp

    This function will just run these tests `n_trials` times and parse the logs
    putting the results in the PARSED_M3_RESULTS_PATH directory.
    """
    print(f"{Colors.BOLD}M3 Experiments, n_trials={n_trials}{Colors.ENDC}")
    try_removing_old_results(PARSED_M3_RESULTS_PATH)

    for run in range(1, n_trials + 1):
        print(f"run={run}")

        # (currently 42 is a placeholder for future parameters we might need)
        # Example: ./run_experiment.sh 3 42
        cmd = f"{RUN_EXPERIMENTS_SCRIPT} 3 42"
        log_file_path = os.path.join(M3_QUERIES_PATH, f"run={run}.log")
        report_cmd_msge(cmd, {"stdout": log_file_path + ".out"})

        process = run_piped_cmd(cmd, log_file_path, verbose=True)

        if process.returncode != 0:
            print(
                f"{Colors.RED} ❌ Experiment returned non-zero exit code:"
                f"{process.returncode}{Colors.ENDC}"
            )
            return False

        print(f"parsing logs for M3 experiments, run={run}")
        time.sleep(1)

        parsed_file = PARSED_M3_RESULTS_PATH + f"m3-run={run}.csv"
        collect_runtimes_from_client_logs(M3_QUERIES_PATH, parsed_file, milestone=3)
        print(f"{Colors.GREEN}Parsed logs can be found in {parsed_file}{Colors.ENDC}")
    print(f"{Colors.GREEN}All milestone 3 experiments completed{Colors.ENDC}")


def try_removing_old_results(results_path):
    if os.path.exists(results_path) and os.listdir(results_path):
        ans = input(
            f"{Colors.YELLOW}Do you want to remove all old results in {results_path}? [y/n]: {Colors.ENDC}"
        )
        if ans.lower() == "y":
            os.system(f"rm -rf {results_path}/*")
        else:
            print(f"Keeping old results in {results_path}")


def check_server_running():
    """Check if server process is running by looking for its process"""
    try:
        output = subprocess.check_output(["ps", "aux"], text=True)
        server_processes = [line for line in output.split("\n") if "server" in line]
        return len(server_processes) >= 1
    except subprocess.SubProcessError:
        return False


if __name__ == "__main__":
    main()
